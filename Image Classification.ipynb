{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec335a63",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5064ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2698d9",
   "metadata": {},
   "source": [
    "# 2. Remove unfit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9967ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdcea4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'cats and dogs-train' # define data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3570268",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png'] # required image extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b045f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each class in the dataset directory\n",
    "for image_class in os.listdir(data_dir):  \n",
    "    # Loop through each image in the current class directory\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):  \n",
    "        # Construct the full file path for the image\n",
    "        image_path = os.path.join(data_dir, image_class, image)  \n",
    "        try:\n",
    "            # Attempt to read the image using OpenCV\n",
    "            img = cv2.imread(image_path)  \n",
    "            # Check the image's file extension/type using imghdr\n",
    "            tip = imghdr.what(image_path)  \n",
    "            \n",
    "            # If the image's extension/type is not in the list of valid extensions\n",
    "            if tip not in image_exts:  \n",
    "                # Print a message indicating the image is invalid\n",
    "                print('Image not in ext list {}'.format(image_path))  \n",
    "                # Remove the invalid image from the directory\n",
    "                os.remove(image_path)  \n",
    "        except Exception as e:\n",
    "            # If an exception occurs (e.g., corrupted image), print the issue\n",
    "            print('Issue with image {}'.format(image_path))  \n",
    "            # os.remove(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597052f",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673c4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee59420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load images from the specified directory and its subdirectories\n",
    "# 'data_dir' is the path to the folder where images are organized in subdirectories by class\n",
    "data = tf.keras.utils.image_dataset_from_directory(data_dir, batch_size=32)\n",
    "\n",
    "# The function automatically:\n",
    "# - Loads all the images from the 'data_dir'\n",
    "# - Assigns labels based on the subdirectory names (each subdirectory represents a class)\n",
    "# - Returns a 'tf.data.Dataset' object that can be used to efficiently handle the image data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4aed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73dfc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the next batch of data (images and labels) from the dataset using the NumPy iterator\n",
    "batch = data_iterator.next()\n",
    "\n",
    "# The batch contains a tuple with two elements:\n",
    "# - The first element is a batch of images (as NumPy arrays)\n",
    "# - The second element is the corresponding labels for those images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eedf10d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 256, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4014063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0594a532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 44.      ,  57.      ,  29.      ],\n",
       "        [ 43.      ,  56.      ,  30.      ],\n",
       "        [ 40.      ,  52.      ,  28.      ],\n",
       "        ...,\n",
       "        [ 85.29144 ,  93.29144 ,  44.291443],\n",
       "        [ 83.359375,  91.359375,  44.359375],\n",
       "        [ 82.      ,  90.      ,  43.      ]],\n",
       "\n",
       "       [[ 43.05768 ,  56.05768 ,  28.057678],\n",
       "        [ 41.678528,  54.678528,  28.678528],\n",
       "        [ 39.077454,  51.077454,  27.077454],\n",
       "        ...,\n",
       "        [ 84.92255 ,  92.92255 ,  43.922546],\n",
       "        [ 84.32147 ,  92.32147 ,  45.321472],\n",
       "        [ 82.95221 ,  90.95221 ,  43.95221 ]],\n",
       "\n",
       "       [[ 44.09613 ,  54.09613 ,  27.09613 ],\n",
       "        [ 43.      ,  53.      ,  28.      ],\n",
       "        [ 40.12909 ,  50.12909 ,  26.12909 ],\n",
       "        ...,\n",
       "        [ 87.82422 ,  95.82422 ,  46.82422 ],\n",
       "        [ 85.359375,  93.359375,  46.359375],\n",
       "        [ 83.92035 ,  91.92035 ,  44.92035 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[180.      , 162.      , 140.      ],\n",
       "        [178.57745 , 159.49933 , 137.8587  ],\n",
       "        [173.82422 , 151.82422 , 130.82422 ],\n",
       "        ...,\n",
       "        [172.78497 , 152.78497 , 128.78497 ],\n",
       "        [169.00781 , 148.00781 , 127.00781 ],\n",
       "        [169.19531 , 148.19531 , 127.19531 ]],\n",
       "\n",
       "       [[177.27826 , 161.33594 , 138.33594 ],\n",
       "        [173.00275 , 155.13788 , 133.07031 ],\n",
       "        [171.31384 , 150.5462  , 129.46875 ],\n",
       "        ...,\n",
       "        [166.0827  , 148.0827  , 124.0827  ],\n",
       "        [164.35938 , 143.35938 , 122.57031 ],\n",
       "        [164.23047 , 143.23047 , 122.44141 ]],\n",
       "\n",
       "       [[170.96484 , 155.96484 , 132.96484 ],\n",
       "        [168.25873 , 152.25873 , 129.25873 ],\n",
       "        [165.39844 , 147.39844 , 125.39844 ],\n",
       "        ...,\n",
       "        [161.52191 , 145.52191 , 120.52191 ],\n",
       "        [162.33685 , 141.33685 , 122.33685 ],\n",
       "        [157.      , 136.      , 117.      ]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb08e9",
   "metadata": {},
   "source": [
    "# 4. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9bde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2fae70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = data.as_numpy_iterator().next()\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a51fb",
   "metadata": {},
   "source": [
    "# 5. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c1b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.8)\n",
    "val_size = int(len(data)*.2)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac63d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca8dcc",
   "metadata": {},
   "source": [
    "# 6. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070fa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088439dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb9118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_env] *",
   "language": "python",
   "name": "conda-env-tf_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
