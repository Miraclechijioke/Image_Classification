{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec335a63",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5064ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2698d9",
   "metadata": {},
   "source": [
    "# 2. Remove unfit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcea4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'cats and dogs-train' # define data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3570268",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png'] # required image extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each class in the dataset directory\n",
    "for image_class in os.listdir(data_dir):  \n",
    "    # Loop through each image in the current class directory\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):  \n",
    "        # Construct the full file path for the image\n",
    "        image_path = os.path.join(data_dir, image_class, image)  \n",
    "        try:\n",
    "            # Attempt to read the image using OpenCV\n",
    "            img = cv2.imread(image_path)  \n",
    "            # Check the image's file extension/type using imghdr\n",
    "            tip = imghdr.what(image_path)  \n",
    "            \n",
    "            # If the image's extension/type is not in the list of valid extensions\n",
    "            if tip not in image_exts:  \n",
    "                # Print a message indicating the image is invalid\n",
    "                print('Image not in ext list {}'.format(image_path))  \n",
    "                # Remove the invalid image from the directory\n",
    "                os.remove(image_path)  \n",
    "        except Exception as e:\n",
    "            # If an exception occurs (e.g., corrupted image), print the issue\n",
    "            print('Issue with image {}'.format(image_path))  \n",
    "            # os.remove(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597052f",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee59420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from the specified directory and its subdirectories\n",
    "# 'data_dir' is the path to the folder where images are organized in subdirectories by class\n",
    "data = tf.keras.utils.image_dataset_from_directory(data_dir, batch_size=8)\n",
    "\n",
    "# The function automatically:\n",
    "# - Loads all the images from the 'data_dir'\n",
    "# - Assigns labels based on the subdirectory names (each subdirectory represents a class)\n",
    "# - Returns a 'tf.data.Dataset' object that can be used to efficiently handle the image data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the next batch of data (images and labels) from the dataset using the NumPy iterator\n",
    "batch = data_iterator.next()\n",
    "\n",
    "# The batch contains a tuple with two elements:\n",
    "# - The first element is a batch of images (as NumPy arrays)\n",
    "# - The second element is the corresponding labels for those images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf10d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4014063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce image size before displaying\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(10,10))\n",
    "\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    resized_img = tf.image.resize(img, (128, 128))  # Resize to smaller dimensions, e.g., 128x128\n",
    "    ax[idx].imshow(resized_img.numpy().astype(int))  # Convert to numpy array and display\n",
    "    ax[idx].title.set_text(batch[1][idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917135ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 4 subplots (1 row, 4 columns) with a figure size of 20x20\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15,15))\n",
    "\n",
    "# Iterate through the first 4 images in the batch (batch[0][:4])\n",
    "for idx, img in enumerate(batch[0][:2]):\n",
    "    \n",
    "    # Display the image in the corresponding subplot\n",
    "    ax[idx].imshow(img.astype(int))  # Convert pixel values to integers before displaying the image\n",
    "    \n",
    "    # Set the title of each subplot with the corresponding label from batch[1]\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb08e9",
   "metadata": {},
   "source": [
    "# 4. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9bde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2fae70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = data.as_numpy_iterator().next()\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe26fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 4 subplots (1 row, 4 columns) with a figure size of 20x20\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(10,10))\n",
    "\n",
    "# Iterate through the first 4 images in the batch (batch[0][:4])\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    \n",
    "    # Display the image in the corresponding subplot\n",
    "    ax[idx].imshow(img.astype(int))  # Convert pixel values to integers before displaying the image\n",
    "    \n",
    "    # Set the title of each subplot with the corresponding label from batch[1]\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a51fb",
   "metadata": {},
   "source": [
    "# 5. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c1b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.8)\n",
    "val_size = int(len(data)*.2)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac63d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca8dcc",
   "metadata": {},
   "source": [
    "# 6. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070fa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088439dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb9118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_env] *",
   "language": "python",
   "name": "conda-env-tf_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
