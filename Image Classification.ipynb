{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec335a63",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5064ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2698d9",
   "metadata": {},
   "source": [
    "# 2. Remove unfit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9967ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdcea4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'cats and dogs-train' # define data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3570268",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png'] # required image extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each class in the dataset directory\n",
    "for image_class in os.listdir(data_dir):  \n",
    "    # Loop through each image in the current class directory\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):  \n",
    "        # Construct the full file path for the image\n",
    "        image_path = os.path.join(data_dir, image_class, image)  \n",
    "        try:\n",
    "            # Attempt to read the image using OpenCV\n",
    "            img = cv2.imread(image_path)  \n",
    "            # Check the image's file extension/type using imghdr\n",
    "            tip = imghdr.what(image_path)  \n",
    "            \n",
    "            # If the image's extension/type is not in the list of valid extensions\n",
    "            if tip not in image_exts:  \n",
    "                # Print a message indicating the image is invalid\n",
    "                print('Image not in ext list {}'.format(image_path))  \n",
    "                # Remove the invalid image from the directory\n",
    "                os.remove(image_path)  \n",
    "        except Exception as e:\n",
    "            # If an exception occurs (e.g., corrupted image), print the issue\n",
    "            print('Issue with image {}'.format(image_path))  \n",
    "            # os.remove(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597052f",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673c4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee59420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load images from the specified directory and its subdirectories\n",
    "# 'data_dir' is the path to the folder where images are organized in subdirectories by class\n",
    "data = tf.keras.utils.image_dataset_from_directory(data_dir, batch_size=32)\n",
    "\n",
    "# The function automatically:\n",
    "# - Loads all the images from the 'data_dir'\n",
    "# - Assigns labels based on the subdirectory names (each subdirectory represents a class)\n",
    "# - Returns a 'tf.data.Dataset' object that can be used to efficiently handle the image data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4aed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator() #convert data to numpy iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73dfc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the next batch of data (images and labels) from the dataset using the NumPy iterator\n",
    "batch = data_iterator.next()\n",
    "\n",
    "# The batch contains a tuple with two elements:\n",
    "# - The first element is a batch of images (as NumPy arrays)\n",
    "# - The second element is the corresponding labels for those images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eedf10d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 256, 256, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4014063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0594a532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[172.05078 , 171.07642 , 139.99951 ],\n",
       "        [172.86328 , 171.9231  , 140.74365 ],\n",
       "        [175.99146 , 175.99146 , 139.99146 ],\n",
       "        ...,\n",
       "        [116.86328 , 105.86328 ,  99.86328 ],\n",
       "        [113.940186, 107.940186,  95.940186],\n",
       "        [112.      , 106.      ,  94.      ]],\n",
       "\n",
       "       [[168.      , 169.      , 128.17969 ],\n",
       "        [167.17969 , 168.17969 , 127.359375],\n",
       "        [167.58984 , 167.58984 , 131.58984 ],\n",
       "        ...,\n",
       "        [130.85962 , 117.85962 , 109.833984],\n",
       "        [111.58984 , 105.58984 ,  93.58984 ],\n",
       "        [111.58984 , 105.58984 ,  93.58984 ]],\n",
       "\n",
       "       [[168.      , 168.      , 130.      ],\n",
       "        [164.13843 , 164.13843 , 126.13843 ],\n",
       "        [165.      , 165.      , 129.      ],\n",
       "        ...,\n",
       "        [156.99219 , 142.99219 , 131.99219 ],\n",
       "        [115.875   , 109.875   ,  97.875   ],\n",
       "        [111.      , 105.      ,  93.      ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 61.      ,  70.      ,  49.      ],\n",
       "        [ 62.17798 ,  71.17798 ,  50.17798 ],\n",
       "        [ 60.316406,  69.31641 ,  48.316406],\n",
       "        ...,\n",
       "        [ 56.      ,  43.      ,  34.      ],\n",
       "        [ 56.      ,  43.      ,  35.      ],\n",
       "        [ 57.      ,  44.      ,  36.      ]],\n",
       "\n",
       "       [[ 65.17969 ,  74.17969 ,  53.179688],\n",
       "        [ 67.58984 ,  76.58984 ,  55.589844],\n",
       "        [ 67.58984 ,  76.58984 ,  55.589844],\n",
       "        ...,\n",
       "        [ 56.      ,  43.      ,  34.      ],\n",
       "        [ 56.      ,  43.      ,  35.      ],\n",
       "        [ 57.      ,  44.      ,  36.      ]],\n",
       "\n",
       "       [[ 70.02515 ,  79.02515 ,  58.025146],\n",
       "        [ 71.      ,  80.      ,  59.      ],\n",
       "        [ 70.86328 ,  79.86328 ,  60.86328 ],\n",
       "        ...,\n",
       "        [ 56.      ,  43.      ,  35.      ],\n",
       "        [ 59.      ,  42.      ,  34.      ],\n",
       "        [ 60.      ,  43.      ,  35.      ]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb08e9",
   "metadata": {},
   "source": [
    "# 4. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9bde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y)) # scale data to min 0, max 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb2fae70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.52438724, 0.45772058, 0.38713235],\n",
       "          [0.56855136, 0.5018847 , 0.43129644],\n",
       "          [0.5740196 , 0.50735295, 0.43676472],\n",
       "          ...,\n",
       "          [0.56976104, 0.50701594, 0.44427082],\n",
       "          [0.55597425, 0.49322918, 0.43048406],\n",
       "          [0.55003065, 0.48728552, 0.42454043]],\n",
       " \n",
       "         [[0.5807598 , 0.51409316, 0.4435049 ],\n",
       "          [0.622886  , 0.55621934, 0.48563114],\n",
       "          [0.6276348 , 0.56096816, 0.4903799 ],\n",
       "          ...,\n",
       "          [0.56976104, 0.50701594, 0.44427082],\n",
       "          [0.55597425, 0.49322918, 0.43048406],\n",
       "          [0.55003065, 0.48728552, 0.42454043]],\n",
       " \n",
       "         [[0.61219364, 0.545527  , 0.47493872],\n",
       "          [0.6543199 , 0.58765316, 0.5170649 ],\n",
       "          [0.6648682 , 0.5982015 , 0.5276133 ],\n",
       "          ...,\n",
       "          [0.56976104, 0.50701594, 0.44427082],\n",
       "          [0.55597425, 0.49322918, 0.43048406],\n",
       "          [0.55003065, 0.48728552, 0.42454043]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.5967132 , 0.4629246 , 0.29486635],\n",
       "          [0.64192945, 0.5100055 , 0.33353487],\n",
       "          [0.6343228 , 0.50380814, 0.3141635 ],\n",
       "          ...,\n",
       "          [0.6427945 , 0.59573567, 0.5329906 ],\n",
       "          [0.7458544 , 0.694874  , 0.6290958 ],\n",
       "          [0.7320116 , 0.66534495, 0.6339724 ]],\n",
       " \n",
       "         [[0.57483196, 0.44149864, 0.26502806],\n",
       "          [0.60329205, 0.46995872, 0.28958046],\n",
       "          [0.61580884, 0.4824755 , 0.2942402 ],\n",
       "          ...,\n",
       "          [0.65958804, 0.6125292 , 0.5575047 ],\n",
       "          [0.71666956, 0.66481453, 0.60464585],\n",
       "          [0.7148452 , 0.6481785 , 0.616806  ]],\n",
       " \n",
       "         [[0.5748521 , 0.43367562, 0.24544032],\n",
       "          [0.57395834, 0.43278188, 0.24454656],\n",
       "          [0.59221816, 0.45104167, 0.25496325],\n",
       "          ...,\n",
       "          [0.7425772 , 0.6955183 , 0.64061636],\n",
       "          [0.6879567 , 0.63305473, 0.58207434],\n",
       "          [0.6817402 , 0.6150735 , 0.5758578 ]]],\n",
       " \n",
       " \n",
       "        [[[0.7755424 , 0.7088757 , 0.50495416],\n",
       "          [0.78342956, 0.7167629 , 0.51284134],\n",
       "          [0.79003525, 0.7233686 , 0.51944697],\n",
       "          ...,\n",
       "          [0.8384804 , 0.7914216 , 0.60318625],\n",
       "          [0.8301471 , 0.7830882 , 0.5948529 ],\n",
       "          [0.83137256, 0.78431374, 0.59607846]],\n",
       " \n",
       "         [[0.7708333 , 0.70416665, 0.5002451 ],\n",
       "          [0.7713235 , 0.70465684, 0.5007353 ],\n",
       "          [0.7946002 , 0.7279335 , 0.52401197],\n",
       "          ...,\n",
       "          [0.8384804 , 0.7914216 , 0.60318625],\n",
       "          [0.8301471 , 0.7830882 , 0.5948529 ],\n",
       "          [0.83137256, 0.78431374, 0.59607846]],\n",
       " \n",
       "         [[0.7674709 , 0.70080423, 0.49688265],\n",
       "          [0.7764706 , 0.70980394, 0.5058824 ],\n",
       "          [0.79163843, 0.7249718 , 0.5210502 ],\n",
       "          ...,\n",
       "          [0.8352941 , 0.7882353 , 0.6       ],\n",
       "          [0.8352941 , 0.7882353 , 0.6       ],\n",
       "          [0.8352941 , 0.7882353 , 0.6       ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.85882354, 0.79607844, 0.5921569 ],\n",
       "          [0.85882354, 0.79607844, 0.5921569 ],\n",
       "          [0.8627451 , 0.8       , 0.59607846],\n",
       "          ...,\n",
       "          [0.88161767, 0.8384804 , 0.6620098 ],\n",
       "          [0.87335324, 0.830216  , 0.6537454 ],\n",
       "          [0.8745098 , 0.83137256, 0.654902  ]],\n",
       " \n",
       "         [[0.85882354, 0.79607844, 0.5921569 ],\n",
       "          [0.8506276 , 0.79093134, 0.5859935 ],\n",
       "          [0.8671736 , 0.8088633 , 0.60494167],\n",
       "          ...,\n",
       "          [0.876495  , 0.83335775, 0.6556861 ],\n",
       "          [0.8666667 , 0.8235294 , 0.64705884],\n",
       "          [0.8745098 , 0.83137256, 0.654902  ]],\n",
       " \n",
       "         [[0.85490197, 0.79607844, 0.5803922 ],\n",
       "          [0.8536765 , 0.8066176 , 0.60269606],\n",
       "          [0.85808825, 0.8188726 , 0.6188725 ],\n",
       "          ...,\n",
       "          [0.8745098 , 0.83137256, 0.6509804 ],\n",
       "          [0.8745098 , 0.83137256, 0.6509804 ],\n",
       "          [0.87058824, 0.827451  , 0.64705884]]],\n",
       " \n",
       " \n",
       "        [[[0.        , 0.00784314, 0.00392157],\n",
       "          [0.        , 0.00784314, 0.00392157],\n",
       "          [0.        , 0.00784314, 0.00490196],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.00784314, 0.00392157],\n",
       "          [0.        , 0.00784314, 0.00392157],\n",
       "          [0.        , 0.00784314, 0.00490196],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.00784314, 0.00392157],\n",
       "          [0.        , 0.00784314, 0.00392157],\n",
       "          [0.        , 0.00784314, 0.00490196],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.01568628, 0.03137255],\n",
       "          [0.        , 0.01568628, 0.03137255],\n",
       "          [0.        , 0.01568628, 0.03768574],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.01568628, 0.03137255],\n",
       "          [0.        , 0.01568628, 0.03137255],\n",
       "          [0.        , 0.01568628, 0.03137255],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.01568628, 0.03137255],\n",
       "          [0.        , 0.01568628, 0.03137255],\n",
       "          [0.        , 0.01568628, 0.03137255],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          ...,\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ]],\n",
       " \n",
       "         [[1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          ...,\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ]],\n",
       " \n",
       "         [[1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          ...,\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          ...,\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ]],\n",
       " \n",
       "         [[1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          ...,\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [0.99987066, 0.7647059 , 0.8745098 ],\n",
       "          [0.99928766, 0.7647059 , 0.8745098 ]],\n",
       " \n",
       "         [[1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          ...,\n",
       "          [1.        , 0.7647059 , 0.8745098 ],\n",
       "          [0.99928766, 0.7647059 , 0.8745098 ],\n",
       "          [0.99607843, 0.7647059 , 0.8745098 ]]],\n",
       " \n",
       " \n",
       "        [[[0.16289254, 0.24524549, 0.26485333],\n",
       "          [0.15984125, 0.2421942 , 0.26180205],\n",
       "          [0.17190659, 0.25425953, 0.27386737],\n",
       "          ...,\n",
       "          [0.07772671, 0.10909926, 0.11951593],\n",
       "          [0.08963791, 0.12493202, 0.12101045],\n",
       "          [0.07637867, 0.1116728 , 0.09990809]],\n",
       " \n",
       "         [[0.13805147, 0.22040442, 0.24001226],\n",
       "          [0.1604272 , 0.24278013, 0.262388  ],\n",
       "          [0.16636316, 0.2487161 , 0.26832396],\n",
       "          ...,\n",
       "          [0.0893076 , 0.12068015, 0.13109681],\n",
       "          [0.09476103, 0.13005514, 0.12613358],\n",
       "          [0.08235294, 0.11764706, 0.10588235]],\n",
       " \n",
       "         [[0.1382037 , 0.22055665, 0.24016449],\n",
       "          [0.14065851, 0.22301145, 0.24261929],\n",
       "          [0.15536152, 0.23771445, 0.2573223 ],\n",
       "          ...,\n",
       "          [0.09546569, 0.12683824, 0.13725491],\n",
       "          [0.08710171, 0.12239584, 0.11847427],\n",
       "          [0.07450981, 0.10980392, 0.09803922]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.11483034, 0.15012446, 0.13835976],\n",
       "          [0.08783988, 0.12705557, 0.123134  ],\n",
       "          [0.06081974, 0.10689338, 0.10402305],\n",
       "          ...,\n",
       "          [0.10494217, 0.20449218, 0.22176681],\n",
       "          [0.14261355, 0.23146158, 0.25553674],\n",
       "          [0.12898284, 0.17135225, 0.20536056]],\n",
       " \n",
       "         [[0.10588235, 0.14534314, 0.1314951 ],\n",
       "          [0.06688113, 0.11792375, 0.10409582],\n",
       "          [0.11599743, 0.16036305, 0.12247051],\n",
       "          ...,\n",
       "          [0.07686887, 0.20603842, 0.24022672],\n",
       "          [0.12625612, 0.25750613, 0.30219534],\n",
       "          [0.14351161, 0.22313783, 0.24940066]],\n",
       " \n",
       "         [[0.09694872, 0.14008598, 0.1243997 ],\n",
       "          [0.06388921, 0.11793333, 0.1031049 ],\n",
       "          [0.28572017, 0.32897997, 0.28719077],\n",
       "          ...,\n",
       "          [0.09442498, 0.2292289 , 0.26452303],\n",
       "          [0.13400735, 0.27199754, 0.31905636],\n",
       "          [0.15530024, 0.23998162, 0.26534927]]],\n",
       " \n",
       " \n",
       "        [[[0.35788143, 0.26768535, 0.14219517],\n",
       "          [0.38736978, 0.2980469 , 0.17299326],\n",
       "          [0.4161305 , 0.33523285, 0.21293658],\n",
       "          ...,\n",
       "          [0.40145528, 0.36179534, 0.23877145],\n",
       "          [0.34772518, 0.31940106, 0.2048024 ],\n",
       "          [0.29964   , 0.27218902, 0.15846354]],\n",
       " \n",
       "         [[0.3873056 , 0.29735935, 0.17178589],\n",
       "          [0.42377633, 0.34043646, 0.21338849],\n",
       "          [0.45277813, 0.37188044, 0.250417  ],\n",
       "          ...,\n",
       "          [0.41184336, 0.37301624, 0.24957594],\n",
       "          [0.36094043, 0.3326163 , 0.21801762],\n",
       "          [0.3174269 , 0.2899759 , 0.17625041]],\n",
       " \n",
       "         [[0.42051584, 0.33288282, 0.2084148 ],\n",
       "          [0.46087062, 0.3810021 , 0.25471532],\n",
       "          [0.48700693, 0.40610927, 0.28710225],\n",
       "          ...,\n",
       "          [0.41685683, 0.3786522 , 0.25531843],\n",
       "          [0.3724431 , 0.34211785, 0.22551803],\n",
       "          [0.33514163, 0.3054388 , 0.18946147]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.04159003, 0.0482035 , 0.01100708],\n",
       "          [0.07990476, 0.08208001, 0.05339587],\n",
       "          [0.10823898, 0.0948101 , 0.07273041],\n",
       "          ...,\n",
       "          [0.4359227 , 0.36439794, 0.10107575],\n",
       "          [0.4655957 , 0.40197742, 0.15734455],\n",
       "          [0.4722329 , 0.40948778, 0.16635053]],\n",
       " \n",
       "         [[0.04625958, 0.05401943, 0.00939238],\n",
       "          [0.1177448 , 0.1214107 , 0.082648  ],\n",
       "          [0.14046222, 0.12724225, 0.09965827],\n",
       "          ...,\n",
       "          [0.4412685 , 0.37163   , 0.09852542],\n",
       "          [0.46193722, 0.39850572, 0.1530619 ],\n",
       "          [0.4569346 , 0.3941895 , 0.15105224]],\n",
       " \n",
       "         [[0.04285386, 0.050697  , 0.00349265],\n",
       "          [0.14293045, 0.14859068, 0.09935661],\n",
       "          [0.16422334, 0.15100338, 0.11934742],\n",
       "          ...,\n",
       "          [0.4389323 , 0.37153798, 0.09003523],\n",
       "          [0.45620406, 0.39302236, 0.14682904],\n",
       "          [0.44371936, 0.38097426, 0.13783701]]]], dtype=float32),\n",
       " array([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1, 1, 0, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data.as_numpy_iterator().next()\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a51fb",
   "metadata": {},
   "source": [
    "# 5. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b694ec35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c1b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.8)\n",
    "val_size = int(len(data)*.2)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fac63d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca8dcc",
   "metadata": {},
   "source": [
    "# 6. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2070fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088439dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4cb9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 2D Convolutional layer with 16 filters, a 3x3 kernel, stride of 1, and ReLU activation\n",
    "# - input_shape: (256, 256, 3) specifies the shape of the input image (256x256 pixels with 3 channels for RGB)\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "\n",
    "# Add a MaxPooling layer to reduce the spatial dimensions (downsampling)\n",
    "# - Pooling reduces the size of the feature maps, helping to reduce computation and prevent overfitting\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Add another Conv2D layer with 32 filters, 3x3 kernel, stride of 1, and ReLU activation\n",
    "# - This layer learns more complex features (such as edges and textures) from the downsampled feature maps\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "\n",
    "# Add another MaxPooling layer to further reduce the size of the feature maps\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Add another Conv2D layer with 16 filters, 3x3 kernel, stride of 1, and ReLU activation\n",
    "# - This layer extracts more specific patterns from the features learned in the previous layers\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "\n",
    "# Add another MaxPooling layer to further reduce the spatial dimensions\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Flatten the 2D feature maps into a 1D vector to prepare for fully connected layers\n",
    "# - This is required before passing the data to the Dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a Dense (fully connected) layer with 256 units and ReLU activation\n",
    "# - This layer learns to combine the features extracted by the Conv2D layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Add the final output Dense layer with 1 unit and sigmoid activation\n",
    "# - Sigmoid activation is used for binary classification (output is between 0 and 1)\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93c98687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy']) # compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "983c2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               3686656   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,696,625\n",
      "Trainable params: 3,696,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34afaf3d",
   "metadata": {},
   "source": [
    "# 7. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f2907fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a0de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir) # create a tensorboard callback to log metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd78a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.7728 - accuracy: 0.5357 - val_loss: 0.6875 - val_accuracy: 0.5872\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 15s 984ms/step - loss: 0.6889 - accuracy: 0.5402 - val_loss: 0.6923 - val_accuracy: 0.4954\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.6905 - accuracy: 0.5223 - val_loss: 0.6871 - val_accuracy: 0.4862\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.6803 - accuracy: 0.5536 - val_loss: 0.7353 - val_accuracy: 0.5046\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.6655 - accuracy: 0.6272 - val_loss: 0.6277 - val_accuracy: 0.7156\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.5793 - accuracy: 0.7143 - val_loss: 0.5106 - val_accuracy: 0.7890\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.4630 - accuracy: 0.7969 - val_loss: 0.3481 - val_accuracy: 0.8716\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.3527 - accuracy: 0.8616 - val_loss: 0.2182 - val_accuracy: 0.9174\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.2120 - accuracy: 0.9107 - val_loss: 0.2081 - val_accuracy: 0.9358\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1452 - accuracy: 0.9487 - val_loss: 0.0691 - val_accuracy: 0.9908\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.0873 - accuracy: 0.9844 - val_loss: 0.0565 - val_accuracy: 0.9908\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.0470 - accuracy: 0.9888 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.0148 - accuracy: 0.9978 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 16s 1s/step - loss: 6.8204e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 16s 1s/step - loss: 7.7520e-04 - accuracy: 1.0000 - val_loss: 7.3321e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 17s 1s/step - loss: 4.8652e-04 - accuracy: 1.0000 - val_loss: 4.8419e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val) # fit model to train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b87c1",
   "metadata": {},
   "source": [
    "# 8. Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0bc75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f3f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e38fa",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffe80eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_test = 'cats and dogs-test' # define data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b346f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load images from the specified directory and its subdirectories\n",
    "# 'data_dir' is the path to the folder where images are organized in subdirectories by class\n",
    "data_test = tf.keras.utils.image_dataset_from_directory(data_dir_test, batch_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ff168",
   "metadata": {},
   "source": [
    "# 9. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f248ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71ae2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Precision()\n",
    "recall = Recall()\n",
    "accuracy = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6638dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n"
     ]
    }
   ],
   "source": [
    "for batch in data_test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    precision.update_state(y, yhat)\n",
    "    recall.update_state(y, yhat)\n",
    "    accuracy.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50693f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6351351141929626\n",
      "Recall: 0.6714285612106323\n",
      "Accuracy: 0.6428571343421936\n"
     ]
    }
   ],
   "source": [
    "final_precision = precision.result().numpy()\n",
    "final_recall = recall.result().numpy()\n",
    "final_accuracy = accuracy.result().numpy()\n",
    "\n",
    "# Print the accumulated metrics for the entire dataset\n",
    "print(f'Precision: {final_precision}')\n",
    "print(f'Recall: {final_recall}')\n",
    "print(f'Accuracy: {final_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed9b94f",
   "metadata": {},
   "source": [
    "# 10. Make test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fd0792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28a476e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dog_11.jpg')\n",
    "#plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c394539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "#plt.imshow(resize.numpy().astype(int))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ade34a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99342996]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e0d695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is Dog\n"
     ]
    }
   ],
   "source": [
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is Dog')\n",
    "else:\n",
    "    print(f'Predicted class is Cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7418d3d",
   "metadata": {},
   "source": [
    "# 11. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c37a01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9928530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','classifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd50222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('models/classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b935d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat_new = new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "854e36f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is Dog\n"
     ]
    }
   ],
   "source": [
    "if yhat_new > 0.5: \n",
    "    print(f'Predicted class is Dog')\n",
    "else:\n",
    "    print(f'Predicted class is Cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce8d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_env] *",
   "language": "python",
   "name": "conda-env-tf_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
